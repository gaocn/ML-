##神经网络

什么是人工智能？感知+理解==>具有决策的能力。

> 学习的能力，才是职能的本质

大数据时代造就了人工智能的发展，使得机器有了学习的能力，进而推动的人工智能的发展。深度学习在90年代就已经出现了，那个时代计算能力太慢，为被人所熟知。2012年一位牛人使用卷积神经网络在[IMAGENET](www.image-net.org)上比赛分类图片得到效果要比机器学习高十几个百分点，至此以后卷积神经网络一炮打响。首先需要了解神经网络，然后再转向深度学习。

为什么人工智能的技术这么厉害？

将以前的机器学习算法进行改进，深度学习和机器学习有什么关系？机器学习领域是非常庞大的，在庞大的机器学习算法中有一类算法叫做神经网络，学者将神经网络进行了扩展和改进，使得神经网络变得扩大一些，加入更多的细节，利用这个扩大的神经网络能够让我们需要预测、分类的效果更好。下图是百度深度学习研究院的ppt，当数据规模小的时候，深度学习和传统人工智能算法差别不大，当数据规模增加时深度学习算法的效果就比传统人工智能算法要好。

![度学习与机器学](imgs_md/深度学习与机器学习.png)

###图像分类：计算机视觉核心任务

深度学习和计算机视觉关系密切，一张图像在计算机中被表示为三维组的形式，每个像素的值从0到255（值越大，表示该像素点越亮）。例如：300\*100\*3，其中300、100可以分别看成是高、宽，图像是有颜色通道的，彩色图有三种颜色通道RGB，因这个RGB通道就是第三个维度，即每一点像素是由三个通道的颜色叠加而形成的。

相同物体在不同角度、不同亮度、物体形态的改变、部分遮蔽、汇入等的情况下如何识别并检测出来

![](imgs_md/遮蔽.png)

![像识别的挑](imgs_md/图像识别的挑战.png)

深度学习的步骤，与机器学习是一样的

1. 收集大量数据并给定标签；
2. 训练一个分类器；
3. 测试，评估

###K-近邻分类算法

如下图所示，根据K值不同得到不同的结果

- 如果K=3，绿色远点的最近的3个邻居是2个红色的小三角和1个蓝色的小正方形，少数服从多数，基于统计的方法，判定绿色的这个待分类点属于红色的三角形一类。
- 如果k=5，绿色圆点的最近的5个邻居是2个红色小三角和3个蓝色正方形，还是少数服从多数，基于统计的方法，哦安定绿色的这个待分类点属于蓝色的正方形一类。

![-近邻举](imgs_md/K-近邻举例.png)

**K-近邻算法描述**

1. 计算已知类别数据集中的点与当前未知类别属性数据集中的点的距离；
2. 按照距离依次排序；
3. 选取与当前点距离最小的K个点；
4. 确定前K个点所在类别的出现频率；
5. 返回前K个点出现频率最高的类别作为当前点预测分类；

KNN算法本身简单有效，它是一种lazy-learning算法，分类器不需要使用训练集进行训练，训练时间复杂度为0。KNN分类的计算复杂度和训练集中的文档数目成正比，即如果训练集中文档总数为N，那么KNN的分类时间复杂度为O(N)。

K值得选择，距离度量和分类决策规则是该算法的三个基本要素。

问题：该算法在分类时有个主要的不足是，当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本上时，该样本的K个邻居中大容量样本占多数？解决办法是不同的样本给予不同权重。

数据集：CIFAR-10

**对于图像数据如何计算距离**
$$
L1 \ Distance：d_1(I_1, I_2) = \sum_p|I_1^p - I_2^p|
$$
这种方式计算距离时，我们也把背景考虑进来的，因此在使用K-近邻时，由于背景噪声的影响会导致结果不准确，因此使用K-近邻计算图片相似度的结果不会很好，是不能使用的，因此常用的方法是神经网络。

![1 Distanc](imgs_md/L1 Distance.png)

```python
import numpy as np
class NearestNeighor:
    def __init__(self):
        pass
    def trai(self, X, y):
        """
        X is N*D where each row is an example. Y is 1-dimesion of size N
        """
        self.Xtr = X
        self.Ytr = y
    def predict(self, X):
        """
        X is N*D where each row is an example we wish to predict label for
        """
        num_test = X.shape[0]
        # make sure that the output type matches the input type
        Ypred = np.zeros(num_test, dtype=self.dtype)
        
        for i in range(num_test):
            # find the nearest trainging image to the i'th test image
            # usig the L1 distance(sum of absolute value different)
            distaces = np.sum(np.abs(self.Xtr - X[i, :]), axis=1)
            min_index = np.argmin(distaces)
            Ypred[i] = self.Ytr[min_index]
        return Ypred
```

**超参数**

这里的距离参数在训练模型时是可以改变的，通过选择不同的距离公式得到不同的距离，称这些可变参数为超参数。如下使用两种方式计算距离
$$
L1（Manhattan）distance：d_1(I_1, I_2) = \sum_p|I_1^p - I_2^p| \\
L2（Euclidean）distance：d_2(I_1, I_2) = \sqrt{\sum_p(I_1^p - I_2^p)^2}
$$
问题：

1. 对于距离如何设定？
2. 对于K近邻的K该如何选择？
3. 如果有的话，其他的超参数该怎么设定呢？

错误的想法是将划分的训练集和测试集多次使用找到最佳参数，事实上测试集非常宝贵，只能在最终验证参数时使用。正确的方式是通过*交叉验证* 找到最优参数。如下图所示，首先将原始数据拆分为训练集和测试集，然后对训练集进行拆分将其中的一份作为验证集。例如：将训练集拆分成5份，其中fold5作为验证集用来调节模型的参数，其他4份作为训练集，则通过多次训练，第一次：<fold1,fold2,fold3,fold4>作为训练集，<fold5>作为验证集，第二次：<fold1,fold3,fold5,fold4>作为训练集，<fold2>作为验证集，第三次：<fold2,fold5,fold1,fold4>作为训练集，<fold3>作为验证集，...如此循环进行多次，用来找到最佳参数，交叉采用不同数据训练的原因是数据有可能不纯，存在有一块或几块数据可能有问题可能存在误差值、异常值导致训练结果偏高或偏低，而采用不同方式交叉训练，将不同训练得到的参数求平均可以消除偏高或偏低的情况，这样得到的模型就比较科学、平均化不至于产生极端效果。

![叉验](imgs_md/交叉验证.png)

###线性分类

如下图所示，这对给定的一张$32*32*3$的图片输入，要做一个分类任务，我们希望找到一组最优权重参数$W$能够输出针对输入在每个类别的得分值。

![性分类](imgs_md/线性分类1.png)

假设类别为10种，则$f(x,W)$的值应该为$10*1$的列向量，而对于给定的输入项将其拉伸为$3072*1$一维列向量，则如下图所示，则权重参数就为$10*3072$的矩阵，若存在截距项b，则b为$10*1$的列向量。由此构成得分函数$f(x,W)=Wx + b$ 

![性分类](imgs_md/线性分类2.png)

例如：将输入为$2*2$的图像拉伸为$4*1$的列向量$x$，得到的权重举证为$W$则得到每一个类别的得到。从图中可以看出在权重矩阵W中的值有大小、有正负，值越大说明对应像素点影响程度比较大，值越小则相应像素点的影响程度较小；而对于权重值为负，则说明对应的像素点的影响是消极的，而正值则表示对应像素点有积极作用。在得到一组得分值后，我们从中去除得分最大的那一类获胜，也就是最终的预测结果。

![性分类3(得分函数举例](imgs_md/线性分类3(得分函数举例).png)

采用权重数据与输入数据进行组合，就相当于完成一个线性分类的工作，每一个类别就能画一条线出来，如下图所示，通过直线划分不同类别，就相当于找出决策边界，通过权重参数找出倾斜度，然后通过b找出截距值，最后就能够得出如下的划分区域。

![性分类](imgs_md/线性分类4.png)

###损失函数（得分函数）

上述得分函数得到的结果有可能是不对的，即预测结果是错的，因此模型需要做到知错能改，将错误给改正过来的能力。如下图所示，对于三个不同的输入图片，根据得分函数得到的结果如下。对于当前输入的得分结果，计算其属于正确类型得分值与其他所有错误类别得分值得差异情况，若错误分类得分比正确分类得分大，这个时候就是分类错误，这个就是损失值，加1意思是定义可容忍程度，例如当前决策模型下，最小容忍损失是1，则预测错误的误差要小于1才能没有损失。
$$
cat = max(0，5.1 - 3.2 + 1) + max(0，-1.7-3.2 + 1) = 2.9 +0 = 2.9 \quad \qquad \qquad\\
car = max(0， 1.3 - 4.9 + 1) + max(0，2.0 - 4.9 + 1) = 0 + 0 = 0 (\lt0认为没有损失) \\
gua = max(0， 2.2 - (-3.1) + 1) + max(0， 2.5 - (-3.1) +1) = 5.3 +5.6 = 10.9 \qquad
$$
损失函数能够判断模型的好坏，损失值越大，模型预测效果越差。

![失函数举](imgs_md/损失函数举例.png)

SVM损失函数
$$
L_i = \sum_{j \ne y_i} max(0,s_j - s_{y_i} + \delta)，其中\delta为可容忍程度
$$
score越大，则距离错误分类的值就越远，此时损失值就越小。

![失函数](imgs_md/损失函数1.png)

**损失函数**
$$
f(x,W) = Wx \\
L = \frac{1}{N}\sum_{i=1}^{N}\sum_{j \ne y_i} max(0，f(x_i；W)_j - f(x_i；W)_{y_i})
$$

例如：样本数据为$x=[1,1,1,1]$四个像素点，每个像素点均为1，有两个模型其权重参数分别为$w_1=[1,0,0,0]$，$w_2=[0.25,0.25,0.25,0.25]$，那么这两个模型与样本数据组合那个模型较好呢？
$$
L_1  = 1 \\
L_2  = 1\\
$$
使用两个权重参数不同模型，得到了相同的预测结果，都会使得最终的得分函数等于1，这就是说选择两者任意一个模型就行了是吗？仔细查看两个模型的权重参数可以看出，对于第一个模型，$w_1$只关注像素中的一个像素点，其他像素点等于任何值与结果没有任何关系；对于第二个模型，$w_2$权重分布均匀，综合考虑到每一个像素点。第二个模型考虑的是整体，而第一个模型只考虑的局部可能导致过拟合(在训练集上表达效果好，而对于测试数据表现不好)，当测试集中的该像素点值不好时预测结果也就差，因此我们希望使用第二个模型，分布稍显均匀。为此，我么需要在引入**正则化惩罚项**
$$
L = \frac{1}{N}\sum_{i=1}^{N}\sum_{j \ne y_i} max(0，f(x_i；W)_j - f(x_i；W)_{y_i}) +  \lambda R(W) \qquad 正则化
$$
正则化惩罚项用于惩罚权重参数的，例如对于两个权重参数$w_1=[1,0,0,0]$，$w_2=[0.25,0.25,0.25,0.25]$，假设惩罚项为$\lambda R(W)=\sum w_i^2$，则惩罚项的值分别为
$$
\lambda R(W_1) = \sum_i w_i^2 = 1 \\
\lambda R(W_2) = \sum_i w_i^2 = \frac{1}{4}
$$
则当损失函数得分值相同时，加上对应的权重惩罚项可以得到第二步模型的损失函数值较小。

**损失函数公式**
$$
L = \frac{1}{N}\sum_{i=1}^{N}\sum_{j \ne y_i} [ max(0，f(x_i；W)_j - f(x_i；W)_{y_i}+ \Delta) ] + \lambda \sum_k \sum_t W^2
$$
注意这里除以$\frac{1}{N}$表示去除样本个数的影响，样本个数对最终模型的好坏是没有影响的。

###Softmax分类器

损失函数得到是模型的得分值，得分值看起来比较麻烦，能不能对得到值进行转换，例如转换成概率值，这样我们就清楚知道某一数据其属于某一类别的概率是多少，看起来非常直观。为此，可以使用Softmax分类器。

![oftmax分类](imgs_md/softmax分类器.png)

**Sigmoid函数** $g(z)=\frac{1}{1+e^{-z}}$，可以将任意实数值映射到[0,1]范围，这样就能够根据得分值得到一个概率值。

Softmax的输出是*归一化的分类概率* ，
$$
f_j(z) = \frac{e^{z_j}}{\sum_k e^{zk}} \Leftarrow softmax函数，得分转化为概率值 \\
$$
 输入是一个向量，向量中元素为任意实数的评分值，输出一个向量，其中每个元素值在[0,1]之间且所有元素之和为1。

![oftmax分类器实](imgs_md/softmax分类器实例.png)

**交叉熵损失(Cross-Entropy Loss)**，通过Softmax得到的概率值不见得是100%，是会存在损失的，我们希望用一个损失函数来衡量概率值。我们需要拿*正确类别Softmax值计算损失值* ，例如上图中属于正确类别即cat类别的概率值为0.13，则若其等于正确类别的概率越低说明预测效果越差，其损失值就越大，因此符合log函数的性质，可以通过log函数计算损失值，并将负值转为正值，就可以得到对于当前预测结果的损失函数为
$$
L_i = - log(\frac{e^{f_{y_i}}}{\sum_j e^{f_i}}) \Leftarrow softmax损失函数，概率值的得分 \\
$$
***SVM损失函数与Softmax损失函数**

SVM损失函数值不好区分，而对于Softmax函数能够很好区分，一般不适用SVM损失函数。

![VM损失函数与Softmax损失函数对](imgs_md/SVM损失函数与Softmax损失函数对比.png)

###最优化

假设$s = f(x;W)$，例如$s = Wx$，则对应的损失函数有
$$
Softmax损失函数 \Rightarrow L_i = -log(\frac{s_{y_i}}{\sum_j e^{s_j}})  \ \  \ \qquad \\
SVM损失函数 \Rightarrow L_i = \sum_{j \ne y_i} max(0, s_j -s_{y_i} + 1) \\
Full损失函数 \Rightarrow L_i = \frac{1}{N}L_i + R(W) \quad \quad \quad\quad\quad \
$$
**前向传播：**从输入$x$到最终得到$loss$的过程，接下来需要通过**反向传播**优化权重参数。通过前向传播得到权重值及其好坏(损失值)，那么能不能使这些权重参数更好一些呢？即找到一组权重参数值，使得损失函数值越低越好，那么此时得到的权重参数值就是最优的。

![失函数_最优](imgs_md/损失函数_最优化.png)

对于每一个迭代求得的梯度，在更新下一次迭代的权重参数$w$时，通过学习率控制下一步得到的权重参数值，学习率过大可能会导致得到不最优解，来回无线迭代，学习率太小跳不出局部最优。通常学习率取值为$0.01,0.0001,...$，通常采取使*用小的学习率，高的迭代次数* 方式求解。有些图可以知道，好的学习率能够得到最低的损失函数值。1 epoch表示跑完所有训练数据得到的结果，不同于一次迭代。

![习](imgs_md/学习率.png)

###反向传播

如何有最终的loss值得到最优的权重值呢？通过反向传播实现。有数据得到损失值得过程为前向传播，而由于损失值沿着相反方向计算什么样的权重参数最优。最优化过程就是在反向传播中体现。

![向传](imgs_md/反向传播.png)

**范例**：损失函数$L=f(x,y,z)=(x+y)z$，样本点为$x=-2，y=5，z=-4$，则可以得到损失值为$L=-12$

![向传播举](imgs_md/反向传播举例.png)

得到损失值后，需要计算$x,y,z$分别对损失函数做了多大贡献，需要得到权重参数$w$与损失函数$L$的关系，得到最优权重参数使得损失函数值最小。
$$
q = x + y \qquad 
\frac{\partial q}{\partial x} = 1 \quad \frac{\partial q}{\partial y} = 1 \\
f=qz \qquad \frac{\partial f}{\partial z} = q \quad \frac{\partial f}{\partial q} = z\\
$$
计算x对损失函数的贡献

1. 算q对f的贡献，$\frac{\partial f}{\partial q} = z = -4$ ，含义是q上升1倍，会使得f值下降4倍，则q应越大越好；
2. 计算x对q的贡献，$\frac{\partial q}{\partial x} = 1$ 

通过反向传播中的**链式法则** 得到x对f的贡献为$1 * -4 = - 4$，同理可以计算y对f的贡献为$-4$，z对f的贡献为$3$ 。

**梯度传递的链式法则** 

![向传播链式法](imgs_md/反向传播链式法则.png)

**范例**：链式法则求解权值参数

![向传播链式法则举](imgs_md/反向传播链式法则举例.png)

简化反向传播计算，直接对sigmoid函数求导，得到的结果也是一样的

![向传播链式法则举例](imgs_md/反向传播链式法则举例2.png)

门单元简化计算

- 加法门单元：梯度均等分配
- MAX门单元：梯度传递为给最大的
- 乘法门单元：梯度互换

![单元及其贡献计](imgs_md/门单元及其贡献计算.png)

##神经网络架构

下图是典型神经网络结构，神经网络有许多层构成，中间层hidden layer（神经元）其实就是权重参数的计算结果。考虑得分函数为$Wx$,则通过神经网络计算后得到的得分结果就为$W_3[W_2(W_1 x)] = output$ ，神经网络中通过权重参数的组合计算最终的输出结果。在神经网络需要明确制定的参数就是$W_1，W_2，W_3$的shape值。

![经网络结](imgs_md/神经网络结构.png)



神经网络具有层次结构，其第二个特点就是非线性，若神经网络是采用线性函数就只能横着一刀竖着一刀切，存在局限性；而采用非线性结构。如下所示
$$
线性方程：f=Wx \\
非线性方程：f = W_2 \ max(0，W_1x)
$$
其中称任何在$W_1x$外添加的函数称为**激活函数**，这里max就是激活函数。什么是激活函数？考虑到线性操作分类能力不是很强，对于非线性的分类需要添加激活函数，例如$Simoid \ \sigma(x) = \frac{1}{1 + e^{-x}}$是[0,1]非线性的函数，每经过一次$Sig(Wx)$操作就是将结果压缩为非线性表达。这就是**为什么添加那么多隐层？**每一个隐藏层结果后都添加一个激活函数，就能够让神经网络以非线性分类方式得出强大结果。
$$
单层神经网络：f=W_2 \ max(0，W_1x) \\
双层神经网络：f= W_3 \ max(0，W_2 \ max(0，W_1x)) \\
$$
$Sigmoid$函数有没有什么缺点？在反向传播中计算$W_1，W_2，W_3，...W_n$对损失函数的贡献时，需要求导并进行梯度累乘操作，在$Sigmoid$函数中当$|x|$稍微大一点时的切线就是趋于水平了，再对其求一次梯度就会得到趋近于0值的贡献，这在后续的求计算梯度累乘过程中就会出现**梯度消失**，即梯度累乘值趋近于零，后续无法继续更新。因此$Sigmoid$函数在神经网络深度较深时无法进行反向传播，神经网络也无法收敛。

**ReLU激活函数**
$$
ReLU = max(0，x)
$$
能够解决梯度消失问题，同时求导比较简单，目前ReLU是首选的激活函数。神经元[^1]的个数越多效果越好，但是神经元越多导致的问题就是过拟合，神经网络最大的问题就是过拟合。下图是一个完整的单层神经网络

![整的神经网络](imgs_md/完整的神经网络层.png)

**神经网络中的过拟合解决方案**

神经网络难以解释的地方在于，每一步设置的权值参数$W_i$我们无法给你正确的解释，不知道为什么会设置成这个值。

**正则化项在神经网络中重要作用**，正则化项$\lambda \sum_i W_i^2$用于惩罚权重参数$W_i$，当正则化值较小的时候，例如$\lambda=0.001$此时图1的“爪子”中数据有很大可能是绿色点或异常点，过拟合现象很严重。当增大正则化惩罚项时，有部分点没有抓取，再次增大正则化惩罚项时，神经网络的结果更平稳了，意味着神经网络的泛化能力更强，神经网络泛化能力越强作用越大。

![则化项的作](imgs_md/正则化项的作用.png)

神经元越多，就越能够表达复杂的模型，但是过拟合的危险越大。为什么说神经元越多分类效果越好？神经元就是相当于权重参数，权重参数越多，相当于伸出来的线或“爪子”也越多。

![经元多少对模型影](imgs_md/神经元多少对模型影响.png)



**数据预处理**

![据预处](imgs_md/数据预处理.png)

**权重初始化** 

通常采用高斯初始化或随机初始化权重参数。例如。$W = 0.01 * np.radom.randn(D, H, shape)$。b的初始化，默认都是将$b=0或b=1$



###Drop_Out

左图中每一层与其他层进行的是全连接操作，当神经元个数很大时进行的计算量就非常大，同时更容易产生过拟合现象。在一次神经网络训练时，在前向传播和反向传播中随机忽略一些神经元进行计算。例如Drop_Out率为40%，表示每一次前向传播和反向传播计算时只保留60%的神经元，每一次计算使用的神经元的随机选择，这样能够降低过拟合的风险。

![rop_ou](imgs_md/drop_out.png)







****

[^1]: [神经网络Demo](https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html)







