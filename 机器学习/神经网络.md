##神经网络

什么是人工智能？感知+理解==>具有决策的能力。

> 学习的能力，才是职能的本质

大数据时代造就了人工智能的发展，使得机器有了学习的能力，进而推动的人工智能的发展。深度学习在90年代就已经出现了，那个时代计算能力太慢，为被人所熟知。2012年一位牛人使用卷积神经网络在[IMAGENET](www.image-net.org)上比赛分类图片得到效果要比机器学习高十几个百分点，至此以后卷积神经网络一炮打响。首先需要了解神经网络，然后再转向深度学习。

为什么人工智能的技术这么厉害？

将以前的机器学习算法进行改进，深度学习和机器学习有什么关系？机器学习领域是非常庞大的，在庞大的机器学习算法中有一类算法叫做神经网络，学者将神经网络进行了扩展和改进，使得神经网络变得扩大一些，加入更多的细节，利用这个扩大的神经网络能够让我们需要预测、分类的效果更好。下图是百度深度学习研究院的ppt，当数据规模小的时候，深度学习和传统人工智能算法差别不大，当数据规模增加时深度学习算法的效果就比传统人工智能算法要好。

![度学习与机器学](imgs_md/深度学习与机器学习.png)

###图像分类：计算机视觉核心任务

深度学习和计算机视觉关系密切，一张图像在计算机中被表示为三维组的形式，每个像素的值从0到255（值越大，表示该像素点越亮）。例如：300\*100\*3，其中300、100可以分别看成是高、宽，图像是有颜色通道的，彩色图有三种颜色通道RGB，因这个RGB通道就是第三个维度，即每一点像素是由三个通道的颜色叠加而形成的。

相同物体在不同角度、不同亮度、物体形态的改变、部分遮蔽、汇入等的情况下如何识别并检测出来

![](imgs_md/遮蔽.png)

![像识别的挑](imgs_md/图像识别的挑战.png)

深度学习的步骤，与机器学习是一样的

1. 收集大量数据并给定标签；
2. 训练一个分类器；
3. 测试，评估

###K-近邻分类算法

如下图所示，根据K值不同得到不同的结果

- 如果K=3，绿色远点的最近的3个邻居是2个红色的小三角和1个蓝色的小正方形，少数服从多数，基于统计的方法，判定绿色的这个待分类点属于红色的三角形一类。
- 如果k=5，绿色圆点的最近的5个邻居是2个红色小三角和3个蓝色正方形，还是少数服从多数，基于统计的方法，哦安定绿色的这个待分类点属于蓝色的正方形一类。

![-近邻举](imgs_md/K-近邻举例.png)

**K-近邻算法描述**

1. 计算已知类别数据集中的点与当前未知类别属性数据集中的点的距离；
2. 按照距离依次排序；
3. 选取与当前点距离最小的K个点；
4. 确定前K个点所在类别的出现频率；
5. 返回前K个点出现频率最高的类别作为当前点预测分类；

KNN算法本身简单有效，它是一种lazy-learning算法，分类器不需要使用训练集进行训练，训练时间复杂度为0。KNN分类的计算复杂度和训练集中的文档数目成正比，即如果训练集中文档总数为N，那么KNN的分类时间复杂度为O(N)。

K值得选择，距离度量和分类决策规则是该算法的三个基本要素。

问题：该算法在分类时有个主要的不足是，当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本上时，该样本的K个邻居中大容量样本占多数？解决办法是不同的样本给予不同权重。

数据集：CIFAR-10