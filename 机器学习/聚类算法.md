期望最大化法（Expectation Maximum，EM）

解决问题：极大似然法用于根据样本数据进行参数估计，但有时观察数据中有“隐含数据”，对于包含“隐含数据”和未知参数的模型，就无法使用极大似然法求解模型分布参数。

EM是一种启发式迭代算法，首先猜测隐含数据（E步），然后基于猜测的数据结合极大似然法求解模型参数（M步）。由于隐含数据是猜测的，因此基于猜测得到的模型是不准确的，接下来继续猜测隐含数据（E步），然后基于猜测和极大似然法求解模型参数，如此循环迭代，直到模型参数基本无变化，则算法收敛并得到模型参数。

范例：KMeans算法是一种EM算法，其中隐含数据为簇的质心，开始时假设K个初始的质心（E步），然后计算得到每个样本最近的质心并把样本归为距离最近质心属于的聚簇（M步），如此循环迭代直到质心不再变化，算法收敛。

算法推导

对于m样本观察数据$x=(x^{(1)},x^{(2)},...,x^{(m)})$，找出样本模型参数$\theta$，目标函数为极大化模型分布的对数似然函数
$$
\theta  = arg \ max_{\theta} \sum_{i=1}^{m} logP(x^{(i)}|\theta)
$$
如果我们得到的观察数据有未观察到的隐含数据$z=(z^{(1)},z^{(2)},...,z^{(m)})$，则对应的目标函数为
$$
\theta  = arg \ max_{\theta} \sum_{i=1}^{m} log \sum_{z^{(i)}}P(x^{(i)}，z^{(i)}|\theta)
$$
上面式子是没有办法求出参数$\theta$的，需要对式子做如下缩放
$$
\sum_{i=1}^{m} log \sum_{z^{(i)}} Q_i(z^{(i)}) \ \frac{P(x^{(i)}，z^{(i)}|\theta)}{Q_i(z^{(i)})} \ge \sum_{i=1}^{m}  \sum_{z^{(i)}} Q_i(z^{(i)}) \ log\frac{P(x^{(i)}，z^{(i)}|\theta)}{Q_i(z^{(i)})} \tag{1}
$$
上述等式引入未知分布$Q_j(z^{(j)})$，且上述不等式用到Jensen不等式
$$
log \sum_j \lambda_jy_j \ge \sum_j\lambda_j  \ log  y_j，\lambda_j \ge 0，\sum_j \lambda_j=1
$$
或者说由于对数函数是凹函数，所以满足$f(E(x)) \ge E(f(x))，若 f(x)为凹函数$。要满足满足Jensen不等式的等号，则有$\frac{P(x^{(i)}，z^{(i)}|\theta)}{Q_i(z^{(i)})} =  c$，其中c为常数。由于$Q_i(z^{(i)})$是一个 分布，所以满足$\sum_{z^{(i)}}Q_i(z^{(i)})=1$ ，从而可得
$$
Q_i(z^{(i)})=\frac{P(x^{(i)}，z^{(i)}|\theta)}{\sum_zP(x^{(i)}，z^{(i)}|\theta)} =\frac{P(x^{(i)}，z^{(i)}|\theta)}{P(x^{(i)}|\theta)} = Q(z^{(i)}|x^{(i)}, \theta)
$$
如果$Q_i(z^{(i)})=Q(z^{(i)}|x^{(i)}, \theta)$，则第(1)式是包含隐藏数据的对数似然的一个下界。如果能极大化这个下界，则也在尝试极大化对数似然。需要最大化下式
$$
\sum_{i=1}^{m}  \sum_{z^{(i)}}Q_i(z^{(i)}) \ log\frac{P(x^{(i)}，z^{(i)}|\theta)}{Q_i(z^{(i)}))}
$$
去掉上式中为常数的部分，则我们需要极大化的对数似然下界为
$$
\sum_{i=1}^{m} \sum_{z^{(i)}} Q_i(z^{(i)}) \ logP(x^{(i)}，z^{(i)}|\theta) \Rightarrow  （M步）
$$
上式也就是EM算法的`M步`，由于$Q_j(z^{(j)})$是一个分布，因此$ \sum_{z^{(i)}}Q_i(z^{(i)}) \ logP(x^{(i)}，z^{(i)}|\theta)$可以理解为$logP(x^{(i)}，z^{(i)}|\theta)$基于条件概率$Q_i(z^{(i)})$的期望，这就是EM算法中的`E步`。

EM算法流程

`输入`：观察数据$x=(x^{(1)},x^{(2)},...,x^{(m)})$，联合分布$P(x,z|\theta)$，条件分布$P(z|z,\theta)$，最大迭代次数为J；

`输出`：模型参数$\theta$

1. 随机初始化模型参数$\theta^{(0)}$

2. 开始EM算法迭代$for \   j  \leftarrow 1 \ to \ J$

   1. E步，计算联合分布的条件概率期望
      $$
      Q_i(z^{(i)}) =  P(z^{(i)} | x^{(i)},\theta^{(i)}) \\
      L(\theta, \theta^{(j)})=\sum_{i=1}^{m}\sum_{z^{(i)}} Q_i(z^{(i)}) \ logP(x^{(i)}，z^{(j)}|\theta)​
      $$

   2. M步，极大化$L(\theta, \theta^{(j)})$，得到$\theta^{(j+1)}$
      $$
      \theta^{(j+1)} =  arg \ max _{\theta} L(\theta, \theta^{(j)})
      $$

   3. ​如果$\theta^{(j+1)}$已收敛，则算法结束。否则继续回到步骤1进行E步迭代