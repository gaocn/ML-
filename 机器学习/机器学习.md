##机器学习 

机器学习主要源自于**人工智能**和**数据科学**，机器学习的核心是建立数据模型，然后依据一些度量标准来验证模型或相互比较。人工智能是要创造出与人类一样的机器，这个方向上又分为不同学派，其中就包括关注与构建人类一样思考的认知系统，而机器学习主要关注的是制造能够自主动作的机器而不管其是否能够像人类一样思考。

**人工智能简介**

人工智能中有需要解决的难题，这里列举主要的5个难题：

1. Intelligent Agents have limited resources(little computational resources processing speend, memory size), AI problems are computationally intractable. How can we get AI agents to give us near real time performance on many interesting problems?
2. All computation is local, but problems have global constrains. How can we get AI agents to address global problems using local computation?
3. Computation logic is fundamentally deductive(演绎逻辑), but many AI problems are abductive(溯因性) or inductive(归纳性) in their nature. How can we get AI agents to address abductive or inductive problems?
4. The world is dynamic, knowledge is limited, but am AI agent must always begin with what it already knows. How can an AI agent ever address a new problem?
5.   Problem solving, reasoning, and learning are complex, but explanation and justification(解释和证明) add to the complexity. How can we get an AI agent to erver explain ot justify it's decisions?

人工智能问题的一些特征：

1. Data arrives incrementally not all the data comes right at the beginning(不是一开始就出现所有数据).

2. Problems often have  a recurring pattern, the same kinds of problems occur again and again. 

3. Problems occur at many different levels of abstraction. 

4. many interesting AI problems are computationally intractable(通过计算难以解决).

5. The world is dynamic, it's constantly changing but knowledge of the world is relative to static.

6. The world is open ended(外界开放式的), but knowledge of the world is relatively limited.

那么问题就变成我们如何能设计出AI智能体(AI agents)来解决具有这些特征的AI问题。有关人工智能Sebatian有另外一种描述：人工智能是计算机软件中不确定性管理(uncertainty management)的技术，即人工智能学科要解决的问题是在你不知道怎么办，该做些什么，有很多原因会导致计算机程序中的不确定性，可能是传感器限制(无法准确告诉你人工智能系统以外的情况)；也可能是你的对手采取迷惑性的行为让你无法了解其真实意图；也可能是随机环境例如在你玩骰子，其随机性导致你无法准确预测出其结果；也可能是迟缓(laziness)，也许你能计算出当前情况，但是计算机程序运行太慢而无法计算出来；也可能是因为完全无知(Plain Ignorance)，许多人对发生的事情一无所知，他们可以知道但只是不关心。所有这些都是不确定性的原因，而人工智能这门科学就是用来处理不确定性以及在决策中管理这些不确定性，从某个角度来说这就是人工智能和机器学习的真谛，即设计一个程序来处理不确定性的输入。

那么通过人工智能的特点，我们应该如何判定一个问题是不是属于人工智能问题呢？考虑一下几个问题，看一下它们是不是人工智能问题或者哪些问题你会通过构建AI agents来解决：

- Answering questions on Jeopardy
- Configuring the dimensions for the basement of a new house
- Tying shoelaces
- Deciding on a route to a new destination
- Making sense of a news broadcast
- Designing a robot that walks on water
- Establishing whether a flower pot can used as a drinking cup
- Deciding whether or not a new animal is a bird

人工智能的目标是重现人类智慧，因此上面所有问题都是人工智能问题，需要针对每一个问题设计出一个AI agents来解决。例如：IBM设计的程序Watson参加过智力竞赛节目Jeopardy，若要设计出Watson AI agents，则它必须能够完成四件基本事情：读懂提示、搜索知识库、确定准确答案、按照问题形式对答案进行润色。基于知识的人工智能有三种基本过程：学习(learning)、记忆(memory)和推理(reasoning)，三者紧密联系。

![基于知识人工智能三个基本过程](imgs_md/基于知识人工智能三个基本过程.png)

学习可能获得某些问题的正确答案并将答案存在某个地方，也可能获得错误的答案则一旦它学到正确的答案也会将其存在在某个地方。学习的知识必须存放在记忆中的某处，若需要利用知识进行推理，则必须从记忆某处调出这些知识，因此记忆用于存放学习到的知识同时提供推理所需要的知识。学习后能够推理，推理的结果通常促进更多的学习；学习后可将成果存在记忆中，但需要记忆中的知识才能学习，知道的越多学到的就越多；推理需要用到记忆中的知识，推理的结果也会存在记忆中，因此这三个过程密切相关，这三个过程合在一起称为**Deliberation Process**。Deliberation Process包含在基于知识的AI Agent的总体架构中。AI agent的总体架构如下所示，输入表现为对外界的感知，输出表现为在外界中的行为，AI agent中有大量Deliberation Process将感知的信息映射为行动

![AI agent主体架构](imgs_md/AI agent主体架构.png)

**人工智能的四个学派**

为了更好的理解人工智能，下图对比不同人工智能思想学派，竖轴分为$thinking \longleftrightarrow acting$，例如当驾驶汽车时是在现实世界中行动，当计划行车路线时是在思考世界。横轴分为$optimally \longleftrightarrow like \ humans$，人具有多种功能且拥有robust intelligence，这种智能相对于任何一项任务无需为最佳但它的适应性很广，能有效完成非常多的任务，而另一端$optimally$能够以最佳方式完成给定任务。通过给定维度得到四种AI agents，从左上角开始逆针依次是：**以最佳方式思考的主体**、**以最佳方式行动的主体**、**像人一样行动的主体**及**像人类一样思考的主体**。基于知识的人工智能属于像人类一样思考这一维度。为了更好理解四个维度，下图中分别列出了对应的实例，许多机器学习算法分析大量数据并确定数据的规律模式，这些算法以最佳方式思考但并不一定像人类那样思考；飞机自动驾驶仪会以最佳方式行动；即兴表演的机器人能随着播放的音乐起舞，它们行动同时行为又像人类一样；语义网是新一代Web技术，能够让Web理解不同的页面和页面上的信息，属于向人类一样思考的主体。

![人工智能的四个学派](imgs_md/人工智能的四个学派.png)

无人驾驶汽车属于像人类一样行动的主体，下面给出四个例子，分别给出其对应于上述的哪一个象限？

- Roomba(automated vacuum) $\rightarrow act \ optimally$
- C-3PO(Star Wars) $\rightarrow act \ like \ humans$
- Siri(Apple virtual assistant) $\rightarrow thinking \ like humans$
- Google Maps(route navigation) $\rightarrow act  \ optimally$

**数据科学**

数据科学的大部分工作是研究数据模式，然后对原因提出假设(hypothesizing a cause)。什么是数据科学家，下图给出了解释：数据科学家掌握了多种不同的技能，数据科学家了解数学和统计学知识使得他们能够在海量数据中找出引人关注的见解，同时还具备编程技能通过代码建立统计模型并从不同数据源中获取数据，此外，他们还知道如何提出正确的问题并将问题转换为全面的分析，分析完成后，他们运用沟通技巧以人们易于理解的方式报告他们的发现。总之，数据科学家能够对庞大的数据集执行复杂的分析，在完成分析后他们还能编制信息图以将发现传递给其他人。

![什么是数据学科家](imgs_md/什么是数据学科家.png)

**机器学习**

**监督学习**可以看做是函数逼近(Function Approximation)，在得到确定的模型或函数后，就能够对其进行**泛化**，这是机器学习中的基本问题，其中的原理是**归纳偏差(Inductive Bias)**，所有的机器学习都与归纳(Induction)而非演绎(Deduction)有关。归纳就是从具体到普遍，而演绎则相反是从普遍规则得出具体实例，类似推理。AI技术最初与演绎推理、逻辑编程有关，它们中有明确的规则，只需要演绎那些直接从这些规则产生的事情，例如某件事类似于A意味着B是一条规则，则给出A就得出B，这就是演绎。

**演绎法(Deduction)、归纳法(Induction)和溯因法(Abduction)**

![归纳、演绎与溯因](imgs_md/归纳、演绎与溯因.png)

如上图所示，为了理解规则、原因和结果的关系，看如下规则Rule：若阴天，就会下雨。则阴天就是原因Cause，下雨就是结果Effect。另一个例子：规则是Bob讨厌Joe，则只要Joe走进来Bob就会离开，原因是Joe走进来，结果是Bob离开。

- **Deduciton**：Given the rule and the case, deduce the effect.
- **Induction**：Given a cause and an effect, induce a rule.
- **Abduction**：Given a rule and an effect, abduce a case.

演绎法具有**保真性(Truth Preserving)**，即若规则是真，原因也为真则结果一定为真。归纳法和溯因法不具有保真性，从具体推导一般结论不一定正确，这就是方法的难点所在。演绎、归纳和溯因是推理的三种基本形式，现实中我们通过对贯彻的数据使用溯因法找到其可能原因，在找出原因后通过归纳得出一个原则，最后通过归纳出的规则利用演绎法预测行的数据，循环使用溯因、归纳、演绎就可对数进行分析。在机器学习中主要使用归纳，拿出一些数据推测其中存在的因果关系，然后归纳出规则，而规则需要有因果关系，因此规则的正确性就是关联。

**非监督学习** 是关于描述(compact description)，它涉及到获取一组数据然后弄清楚如何通过这样或那样的方式分割数据。将描述看做是非监督学习，而将监督学习看做是函数逼近，则可以先通过非监督学习进行信息压缩，然后通过函数逼近得到有效结果。

```mermaid
graph LR
  A[Description]
  B[funciton approximation]
  I-->|input| A
  A -->|summaries| B
  B -->|labels|O
```

学习概念和构建模型是机器学习的核心，下面介绍机器学习的基本要素以便能够更好的区分不同的机器学习算法：

| 要素                   | 关键概念                                                     |
| ---------------------- | ------------------------------------------------------------ |
| WHAT is been learnded? | Parameters, Structure, Hidden Concepts(不同客户喜欢不同类型电影) |
| WHAT FROM              | 不同机器学习关注的目标信息不同，监督学习中有样本和标记，而非监督学习则缺少目标标记，而增强学习中主体通过反馈进行学习，并从环境中评估结果中例如：well done or that works |
| WHAT FOR?              | prediction, Diagnosis, Summarization                         |
| HOW to learn?          | passive(学习主体是观察者对数据本身无影响), active, online(数据生成的同时进行学习), offline(数据生成后再进行学习) |
| OUTPUTS                | classification, regression                                   |
| DETAILS                | 生成法(generative, model data as generally as possible), 判别法(discriminative, seeks to distinguish data) |

## 模型评估和验证

机器学习的的最终目标是获得可以不断学习和改进的数据模型，本质上，机器学习根据以前样本中的数据进行推理。

###中心测量方法(Measures of Center)

**众数(Mode)**：众数用于描述数据的集中趋势。偏斜分布的样本众数出现在偏斜处，均匀分布没有众数，而存在两个或多个明显清晰的趋势分布视为**多峰分布**是存在多个众数的，例如女性鞋码为7而男性鞋码为9。而针对分类数据，众数是出现在X轴上最高频率处的任何值。众数是可用于描述任何数据类型，数据集中的所有分值不一定会影响众数，若从总体中取出若干组样本，从中找到每个样本的众数，这些众数将会将相同？(错，众数随样本不同而不同)，众数不存在计算公式。我们无法利用一个等式来描述众数，这就是为什么经常使用平均数。

**平均值(Mean)**将其全部数值考虑进去，能都用一个公式进行描述。均值的特性：1. 分布中的所有数据都会影响平均值；2. 取自相同总体的多个样本具有相同均值；3. 样本均值可用于对样本所来自的总体进行推论。当样本中有异常值时，均值是具有**误导性的**，会将平均值拉向异常值方向，造成**偏斜分布**，这就使得这个均值不具有代表性。众数不会受到异常值的影响，而平均值则会受异常值影响很大。

**中位数(Median)**那么应该怎么做才能让中位数称为有用的，能够实际代表数据的统计值呢？将数据排序，然后删除第一个和最后一个数字，然后依次删除第二个，导数第二个，直到最后剩下一个或俩个。含有异常值的中位数会受到影响，但是影响不会像平均值那样大。

###离散趋势分析

当两个分布均值、中位数、总数相同时，例如都是高斯分布，那么应该如何比较这两组数据呢？可以通过查看不同分布的**离散程度**，那么应该如何衡量数据的分散程度呢？可以通过对比两组数据的最大值和最小值之差来判断它们之间的范围$Range=\{max - min\}$来判断数据的离散程度，然而当新数据加入的时候这个范围有时候是会变化的，这个值域不包括细节信息仅仅是两个数据的基础上得到的，这种极端值不可能代表分布中的其余值。特别的，当存在异常值时，就会使得这个值域异常的小或大，因此值域不可能准确地代表数据的差异性，特别是在异常值存在时。

**Cutting off tails **统计学中处理异常值的一种方式是忽略分布中的上尾和下尾。忽略尾部是指忽略掉较低的25%(**四分位**)和较高的25%()，例如假设有8个数据值，忽略掉最小的$8*0.25=2$个以及最大的$8*0.25=2$个，只关心中间的数值。通常称$Q1$为**第一个四分数**，则总共有$Q1、Q2、Q3、Q4$这四个四分位数，其中$Q2$就是中位数(Median)。而**四分位差**($Interquatile \ Range, IQR$)为：$Q3 - Q1$，有关$IQR$相关题目如下，判断正确与否：

- 约50%的数据属于IQR $\checkmark$，特别是大数据集中；
- IQR受到数据集中每个值的影响$\times$，不会受到所有数据的影响；
- IQR不受异常值的影响$\checkmark$

**异常值(Outlier)** 在**统计学**上有专门的方法计算一个值是否是异常值，如果一个值小于第一个四分位数减去1.5倍的$IQR$，或者这个值大于第三个四分位数加上1.5倍的$IQR$，则称之为异常值。
$$
Outlier \lt Q1 - 1.5*IQR \quad || \quad Outlier \gt Q3 + 1.5*IQR
$$
**箱线图(Box Plot)** 箱线图结合最大值、最小值以及四分位数和四分位差，将这些元素放在一个单元统一展示，如图所示。

![箱线图](imgs_md/箱线图.png)

那么有一个问题是：平均值是否总是在Q1和Q3之间？答案是否，虽然通常情况下是的，如下面的例子，可以求出平均值为8.62，但是Q3=3。
$$
0, 1, 1/, \quad 1, 2, 2/, \quad \underbrace{2}_{Q2}, 2, 2, \underbrace{3}_{Q3}/,\quad 3, 3, 90 \\
mean = 8.62
$$
从上面可以知道，值域和IQR都无法将所有数据考虑进来，两个完全不同的数据集也可以有相同的IQR，例如正态分布，双峰分布和均匀分布，因此IQR并不能满足我们对数据集的信息提取需求。我们需要一个数值既能够反映数据分布，又可以将所有数据考虑进来，从而反映出数据的差异性。

**偏差(Deviaton from Mean)**：$(x_i - \overline{x})$，**离差平方和**(Sum of Square，SS)：$\sum_i^N(x_i - \overline{x})^2$，**方差**(Deviation)：$\sigma^2 =\frac{1}{N} \sum_i^N(x_i -\overline{x})^2$，方差与离差平方和的关系及其几何意义如下图所示，其中橙色矩形的面积就是方差的值。对于有单位的数据方差的单位则是原来单位的平方，为此需要使用**标准差**(Standard Deviation，SD)：$\sigma = \sqrt{\frac{1}{N}(x_i - \overline{x})^2}$，这样的到数据就与样本数据单位一致了。

![方差与离差平方和的关系](imgs_md/方差与离差平方和的关系.png)

**SD的重要性** 事实证明，在正态分布中$平均值=中位数=众数$，同时这些统计量位于分布的中心，标准差具有重要意义，大约68%的数据与平均值的偏差不超过1个标准差，而有95%的数据与平均值的偏差不超过2个标准差。实际上我们可以粗略估计与平均值存在任意标准差偏差的数据的规模，因为已有科学家把对应的结果给计算出来的，我们只需要查表即可。

![标准差的重要性](imgs_md/标准差的重要性.png)

**贝塞尔校正(Bessel's Correction)** 通常抽样中会低估了总体中差异性的数量，因为抽样往往是总体居于中间的值，特别是在正态分布中多数值居于中间位置，因此当我们从正态分布的总体中抽样时，多数值也在附近。因为多数值在这个区域类，因此抽样中的差异性将少于整个总体的差异性，为了纠正这个现象，我们使用贝塞尔校正系数，把标准差中的除以N替换为除以N-1得到样本的标准差为：$s = \sqrt{\frac{1}{N-1}(x_i - \overline{x})^2}$，用s表示修正后的标准差，除以N-1可以让标准差稍稍大一点以符合总体标准差。通常使用**样本标准差(Sample Standard Deviation)**估算真实总体标准差$\sigma$，在计算样本标准差和估算总体标准差时是有区别的，具体如下例所示：
$$
Samples：5 、 2、1、0、7 \qquad \overline{x} =3 \\
Square \ Deviation：4、1 、4、9、16 \\
Sum \ of \ Squares： \sum(x_i -\overline{x}) = 34 \\
Standard \ Deviation \ of \ Sample = \sqrt{\frac{34}{5}} \\
Standart \ Deviation \ of \ Population \approx  \sqrt{\frac{34}{5-1}} = \sqrt{\frac{34}{4}}
$$

###分类指标和回归指标

在构建机器学习模型时，我们首先要选择性能指标，然后测试模型的表现如何。在可以选择性能指标之前，首先务必要认识到，机器学习研究的是如何学习根据数据进行预测。对于监督式机器学习，我们将重点关注那些创建分类或创建预测回归类型的已标记数据。

此外，在测试模型时，也务必要将数据集分解为训练数据和测试数据。如果不区分训练数据集和测试数据集，则在评估模型时会遇到问题，因为它已经看到了所有数据。我们需要的是独立的数据集，以确认模型可以很好地泛化，而不只是泛化到训练样本。

在分类中，我们想了解模型隔多久正确或不正确地识别新样本一次。而在回归中，我们可能更关注模型的预测值与真正值之间差多少。对于分类，我们处理的是根据离散数据进行预测的模型，预测结果评价指标有**准确率**、**精确率**、**召回率**和**F分数**。对于回归，评价指标有**平均绝对误差**和**均方误差**。

####分类指标

**准确率(Precision)**被描述为在特定类的所有项中正确分类或标记的项的数量。举例而言，如果教室里有 15 个男孩和 16 个女孩，人脸识别软件能否正确识别所有男孩和所有女孩？如果此软件能识别 10 个男孩和 8 个女孩，则它识别男孩和女孩的准确率分别为 66% 和 50%：
$$
Accuracy = \frac{no. \ of \ items \ in \ a \ class \ labeled \  correctly}{all \ items \ in \ that \ class}
$$
**准确率的缺陷** 

1. 对于有偏分布(skewed data)的数据不适用，例如有很多数据点，其中一小部分归入一类而其余很多归入其他类中，例如上万人员中寻找涉嫌欺诈而身缠法律诉讼的人，这里准确率就不太适用，因为其中一类数据很少；
2. 准确性不能很好的制定出你想要的结果，准确度可能并非正确的指标。例如目标是猜测涉嫌欺诈而身缠法律诉讼的人或者目标是猜测无法律诉讼缠身的人；

**混淆矩阵(Confusion Matrix)** 

| Prediction  | Observation           |                       |
| ----------- | --------------------- | --------------------- |
|             | Admitted(1)           | Rejected(0)           |
| Admitted(1) | True Positive (TP)，  | False Positive (FP)， |
| Rejected(0) | False Negative (FN)， | True Negative (TN)，  |

假如某个班级有男生80人，女生20人，共计100人。目标是找出所有女生。现在某人挑出50人，其中20人是女生，另外还错误的把30个男生也当作女生挑选出来了。

|            | 相关，正类                           | 无关，负类                           |
| ---------- | ------------------------------------ | ------------------------------------ |
| 被检索到   | TP，正类判定为正类，确实是女生       | FP，负类判定为正类，男生被判定为女生 |
| 未被检索到 | FN，正类判定为负类，女生被判定为男生 | TN，负类判定为负类，男生被判定为男生 |

通过上述表格，可以清楚的得到：TP=20，FP=30，FN=0，TN=50

**True Positive Rate(Sensitivity)** TPR指标衡量模型检测正例的效果，例如用模型检测病人是否患癌症，TP表示患病的人被正确的检测出来了，而FN则是患病的人被认为是正常的，这时候结果就严重的，在这个问题上需要考虑TPR，否则好多人会因为这个模型而受难。

$$
TPR =  \frac{True  \ Positives}{True \  Positives + False \  Nagetives}
$$
**True Negative Rate** TNR指标衡量模型检测负例例的效果，例如用模型检测病人是否患癌症，TP是没患癌症的人被正确的检测出来了，TN是没患病的人被检测出来患有癌症。

$$
TNR = \frac{True \ Negative}{False \ Positive + True \ Negative}
$$
为什么说精度经常是不准确的、有欺骗性？例如有100个样本，其中有90个样本是属于1这个类别，而10个样本属于0这个类别，让分类器预测，假设模型全部预测为1类别，则精度也有90%，因此精度在样本非常不平衡的条件下是非常不准确的。**查全率(Recall)和查准率(Precision)** 查全率为预测为正例(TP)占所有观测值的比例(TP+FN)，而查准率为预测值为TP占所有预测为正例值的比例(TP + FP)。

**F1 分数** F1 分数会同时考虑精确率和召回率，以便计算新的分数。可将 F1 分数理解为精确率和召回率的加权平均值，其中 F1 分数的最佳值为 1、最差值为 0。
$$
F1 = \frac{2 *Precision * Recall}{Precision + Recall}
$$

####回归指标

回归是根据连续数据进行预测的模型，我们更关注预测的接近程度。例如，对于身高和体重预测，我们不是很关心模型能否将某人的体重 100% 准确地预测到小于零点几磅，但可能很关心模型如何能始终进行接近的预测，如可能与个人的真实体重相差 3-4 磅。

**平均绝对误差(Mean Absolute Error， MAE)** 在统计学中可以使用绝对误差来测量误差，以找出预测值与真实值之间的差距。平均绝对误差的计算方法是，将各个样本的绝对误差汇总，然后根据数据点数量求出平均误差。通过将模型的所有绝对值加起来，可以避免因预测值比真实值过高或过低而抵销误差，并能获得用于评估模型的整体误差指标。
$$
MAE = \frac{1}{N} \sum_{i=1}^{N} |h_i - y_i|
$$
**均方误差(Root Mean Square Error, RMSE)** 是另一个经常用于测量模型性能的指标。与绝对误差相比，残差（预测值与真实值的差值）被求平方。对残差求平方的一些好处是，自动将所有误差转换为正数、注重较大的误差而不是较小的误差以及在微积分中是可微的（可让我们找到最小值和最大值）。
$$
RMSE = \frac{1}{N} \sum_{i=1}^{N} (h_i - y_i)^2
$$
**回归分数函数** 除了误差指标之外，scikit-learn还包括了两个分数指标，范围通常从0到1，值0为坏，而值1为最好的表现。回归的默认指标是“分数越高越好”

- **R2分数** 用来计算真值预测的可决系数。在 scikit-learn 里，这也是回归学习器默认的分数方法。
- **可释方差分数** 

####误差原因

在模型预测中，模型可能出现的误差来自两个主要来源，即：因模型无法表示基本数据的复杂度而造成的偏差（bias），或者因模型对训练它所用的有限数据过度敏感而造成的方差（variance）。

- 偏差造成的误差  => 精度和欠拟合

  如果模型具有足够的数据，但因不够复杂而无法捕捉基本关系，则会出现偏差。这样一来，模型一直会系统地错误表示数据，从而导致预测精度低。这种现象叫做欠拟合（underfitting）。

  简单来说，如果模型不适当，就会出现偏差。举个例子：如果对象是按颜色和形状分类的，但模型只能按颜色来区分对象和将对象分类（模型过度简化），因而一直会错误地分类对象。或者，我们可能有本质上是多项式的连续数据，但模型只能表示线性关系。在此情况下，我们向模型提供多少数据并不重要，因为模型根本无法表示其中的基本关系，我们需要更复杂的模型。

- 方差造成的误差  => 精度和过拟合

  在训练模型时，通常使用来自较大母体（训练集）的有限数量样本。如果利用随机选择的数据子集反复训练模型，可以预料它的预测结果会因提供给它的具体样本而异。在这里，方差（variance）用来测量预测结果对于任何给定的测试样本会出现多大的变化。

  出现方差是正常的，但方差过高表明模型无法将其预测结果泛化到从中抽取训练样本的较大母体。对训练集高度敏感也称为过拟合（overfitting），而且通常出现在模型过于复杂或我们没有足够的数据支持它时。通常，可以利用更多数据进行训练，以降低模型预测结果的方差并提高精度。

**改进模型的有效性** 我们可以看到，在给定一组固定数据时，模型不能过于简单或复杂。如果过于简单，模型无法了解数据并会错误地表示数据。但是如果建立非常复杂的模型，则需要更多数据才能了解基本关系，否则十分常见的是，模型会推断出在数据中实际上并不存在的关系。**关键在于**通过找出正确的模型复杂度来找到最大限度降低偏差和方差的最有效点。当然，数据越多，模型随着时间推移会变得越好。

要详细了解偏差和方差，建议阅读 Scott Fortmann-Roe 撰写的这篇文章。http://scott.fortmann-roe.com/docs/BiasVariance.html

**特征数量对偏差、方差的影响** 

高偏差算法是对训练数据关心很少，是一种过度简化的算法，不关心训练过程中训练数据给你的反馈；而高方差算法对数据过度关心，它不能很好的推广到以前未曾见过的新情况，基本上只是记住训练示例而已，一旦新的数据点不完全像训练示例就不知道该如何去做了。另一种说法：高偏差算法在训练集上有很高误差，例如在回归时会出现低R平方值或较大残差平方和$lower \ R^2 \ and larger \ SSE$，高方差算法在训练集有很好很好的拟合度但对于测试数据却拟合不佳，不能泛化。

除了选定用来训练模型的数据子集外，您使用的哪些来自给定数据集的特征也会显著影响模型的偏差和方差？使用少量的特征就会进入经典的高偏差型领域，因为没有关注足够多的数据，是一种过度简化的情况。为了尽量最小化预测误差，当我们仔细调整模型参数增加特征时，就会进入高方差型领域，此时会出现过拟合现象。

###训练测试分离与交叉验证

为什么要将样本分为测试集和训练集？使用各自训练和测试数据使得你能基于独立数据集评估分类器或回归的性能；此外，使用各自的训练和测试数据作为过度拟合的检查因素。

 ```python
import numpy as np
from sklearn.model_selection import train_test_split
X, y = np.arange(10).reshape((5, 2)), range(5)
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)
 ```

**交叉验证** 样本数据是要划分为训练集、测试集，那么存在一种情况导致切分后数据分布不均衡，例如在测试集中存在异常点比较多或训练集中异常点比较多，这就导致在训练模型是得到的结果不会很准确。例如将样本集切缝成大小相同的五个部分，如各自有100个数据，取其中的一份作为测试集，其余的4份作为训练集，每一次迭代的训练集和测试集不同，通过交叉的方式训练模型，有训练得到的5个模型共同得出最终的模型（如求5个模型结果的平均值作为最终结果），这种训练模型的方式称为交叉验证。

sklearn.model_selection.**KFold**(n_folds=3, shuffle=False, random_state=None)

- n_folds：需要将观测集切分成几份
- shuffle：是否随机排列观测集
- random_state：shuffle=True时，指定随机排列观测集的random seed

```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

admissions = pd.read_csv(r'G:\data\admissions.csv', na_filter=True)
admissions['actual_labels'] = admissions['admit']
admissions = admissions.drop('admit', axis=1)
kf = KFold(5, shuffle=True, random_state=8)
lr = LogisticRegression()

accurates = cross_val_score(lr, admissions[['gpa']], admissions['actual_labels'], scoring='roc_auc', cv=kf)
# array([0.70175439, 0.5023511 , 0.60750507, 0.59722222, 0.67074074])
average_accuracy = sum(accurates) / len(accurates)
#  0.6159147034200947
```
KFold只是将数据划分为大小相同的若干部分，不会对数据进行任何类型的乱排序，如果数据中在类别上存在某些模式，那么这些模式就会反映在大量特定的标签中，最终体现在验证的特定KFold上，这个可能不是我们需要的结果。

**GridSearchCV参数选择** GridSearchCV 用于系统地遍历多种参数组合，通过交叉验证确定最佳效果参数。它的好处是，只需增加几行代码，就能遍历多种组合。

```python
from sklearn import svm, datasets
from sklearn.model_selection import GridSearchCV
iris = datasets.load_iris()

#这时，会自动生成一个不同（kernel、C）参数值组成的“网格”:
#    ('rbf', 1)	    ('rbf', 10)
#    ('linear', 1)	('linear', 10)
#各组合均用于训练 SVM，并使用交叉验证对表现进行评估。
parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}
svc = svm.SVC()
clf = GridSearchCV(svc, parameters)
clf.fit(iris.data, iris.target)
# 来获得参数值
clf.best_params_ 
sorted(clf.cv_results_.keys())
```

### 维度灾难(Corse of Dimensionality)

随着特征或维度的增加，我们为了准确泛化所需要的数据量也呈指数增长。这就意味正每一次增加新的特征建立模型时，我们训练模型需要的数据将呈指数级增长，例如使用kNN算法时会因为维度灾难导致算法复杂度激增而无法。

###学习曲线

让我们根据模型通过可视化图形从数据中学习的能力来探讨偏差与方差之间的关系。机器学习中的学习曲线是一种可视化图形，能根据一系列训练实例中的训练和测试数据比较模型的指标性能。在查看数据与误差之间的关系时，我们通常会看到，随着训练点数量的增加，误差会趋于下降。由于我们尝试构建从经验中学习的模型，因此这很有意义。我们将训练集和测试集分隔开，以便更好地了解能否将模型泛化到未见过的数据而不是拟合到刚见过的数据。

在学习曲线中，当训练曲线和测试曲线均达到稳定阶段，并且两者之间的差距不再变化时，则可以确认模型已尽其所能地了解数据。

- **偏差**，在训练误差和测试误差收敛并且相当高时，这实质上表示模型具有偏差。无论我们向其提供多少数据，模型都无法表示基本关系，因而出现系统性的高误差。
- **方差**，如果训练误差与测试误差之间的差距很大，这实质上表示模型具有高方差。与偏差模型不同的是，如果有更多可供学习的数据，或者能简化表示数据的最重要特征的模型，则通常可以改进具有方差的模型。

**理想的学习曲线** 模型的最终目标是误差小并能很好地泛化到未见过的数据（测试数据）。如果测试曲线和训练曲线均收敛，并且误差极低，就能看到这种模型。这种模型能根据未见过的数据非常准确地进行预测。

**模型复杂度** 与学习曲线图形不同，模型复杂度图形呈现的是模型复杂度如何改变训练曲线和测试曲线，而不是用以训练模型的数据点的数量。一般趋势是，随着模型增大，模型对固定的一组数据表现出更高的变化性。

**学习曲线与模型复杂度之间有何关系？**如果我们获取具有同一组固定数据的相同机器学习算法的学习曲线，但为越来越高的模型复杂度创建几个图形，则所有学习曲线图形均代表模型复杂度图形。这就是说，如果我们获取了每个模型复杂度的最终测试误差和训练误差，并依据模型复杂度将它们可视化，则我们能够看到随着模型的增大模型的表现有多好。