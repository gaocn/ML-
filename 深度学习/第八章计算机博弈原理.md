## 第八章 神经网络应用之计算机博弈原理

计算机博弈是指由计算机参与一方或双方的游戏，例如棋类游戏，有明确的规则，可以很容易建立**博弈树**，博弈树把双方所有可能走的过程建立为一棵树，通过查找博弈树得到下一步的克可行方案。

**计算机围棋发展史**

- 早期主要还是浅层遍历+局面评估函数的 斱法，例如其中一种局面评估的方法:考虑每颗棋子发出一定的射线“辐射”影响 力。当无法通过博弈树找到全部最优解时，一个解决方案是**局面评估函数**，但是对于围棋难以通过棋艺直觉形成合适的局面评估函数。中山大学教授陈志行的“手谈”。

- 蒙特卡罗树搜索[^1]的思路，典型软件: Fuego，Pachi 
- 10年前就有把卷积神经网络应用于围棋的思路，幵非Deepmind独创，但Deepmind很好地把多种思想和技巧糅合 在一起，开发利用Google在硬件和编程 上的强势基础，终于把计算机围棋水平上 升到新高峰 

在2010年由Demis Hassabis ，Shane Legg和Mustafa Suleyman成立创业公司，Hassabis和Legg最初在伦敦大学生命科学系的盖茨比计算神经科学小组里相识。Horizons Ventures和Founders Fund两家风险投资公司对DeepMind迚行了投资， 除此之外还有企业家Scott Banister和伊隆·马斯克的投资。Jaan Tallinn是公司早期的 投资者和顾问。在2014年，DeepMind荣获了剑桥大学计算机实验室的“年度公司” 奖项。 DeepMind创造了一个以人类的斱式学习如何玩电子游戏的人工神经网络，幵发这个 神经网络可以接入一个外部的存储器，就像一个传统的图灵机一样，使得一台电脑可 以模拟人类的短期记忆。 2014年1月26日，Google宣布已经同意收购DeepMind科技。这次收购发生在2013 年Facebook与DeepMind科技结束谈判之后。在这次收购之后，DeepMind科技改名 为Google DeepMind[^3]，收购的价格估计在4亿美元到5亿欧元之间。 

 





### 参考文献

[^1]: A survey of monte carlo tree search methods
[^2]: BETTER COMPUTER GO PLAYER WITH NEURAL NETWORK
[^3]: Mastering the Game of Go with Deep Neural Networks and Tree Search
[^4]: Mimicking go experts with convolutional neural networks
[^5]: Reinforcement learning and simulation-based search

