#Scipy使用（一）

```python
import numpy as np
from scipy import linalg, optimize

#查看方法的注释
np.info(optimize.fmin)
np.source(optimize.fmin)

```

##一、Scipy文件操作（[`scipy.io`](https://docs.scipy.org/doc/scipy/reference/tutorial/io.html)）

用于将数据导入导出成不同格式的文件。常用的是与MATLAB数据文件进行交互。

| 方法                                     | 说明                        |
| -------------------------------------- | ------------------------- |
| loadmat(file_name[,mdict, appendmat])  | 加载MATLAB数据文件              |
| savemat(file_name, mdict[, appednmat]) | 将字典或数据保存为MATLAB数据文件.mat格式 |
| whosmat(file_name[, appendant])        | 查看MATLAB文件的数据信息           |

```python
from scipy import io as sio
from numpy as np

mat_contents = sio.loadmat('octave_a.mat')
#{'a': array([[[  1.,   4.,   7.,  10.],
#        [  2.,   5.,   8.,  11.],
#        [  3.,   6.,   9.,  12.]]]),
# '__version__': '1.0',
# '__header__': 'MATLAB 5.0 MAT-file, Created on: 2013-02-17 21:02:11 UTC',
# '__globals__': []}

vect = np.arange(10)
sio.savemat('np_vect.mat', {'vect': vect})

#whosmat返回元组列表，每一数组对应一个元组(name, shape, data_type)
sio.whosmat('octave_a.mat')
#[('a', (1, 3, 4), 'double')]

#读取图片文件与matplotlib中的imread类似
#若报错，需要安装pillow包
from scipy import misc 
imdata = misc.imread("demo.jpg")
```

##二、线性代数（[`scipy.linalg`](https://docs.scipy.org/doc/scipy/reference/tutorial/linalg.html)）

###2.1 matrix VS ndarray？ 

在numpy中有两种用于矩阵计算的类，一种是numpy.matrix类，另一种是numpy.ndarray类。numpy.matrix类提供了矩阵运算常用的接口，例如: `*` 在matrix对象中就是矩阵的乘法而在ndarray对象中这不是，ndarray中需要使用a_ndarr.dot(b_ndarr)。`尽管matrix使用很方便，但是不建议使用，基于ndarray对象提供的接口更多，而引入matrix类会产生混淆！ 矩阵的所有运算一样能够使用ndarray计算出来`   

```python
import numpy as np
from scipy import linalg

#matrix对象
mat = np.mat('[1 2;3 4]')
mat.T
mat.I
mat * mat.T

#ndarray对象
A = np.array([[1,2],[3,4]])
linalg.inv(A)
b = A.T
A.dot(b)

```

###2.2 linalg基本函数

**方阵的逆：inv**

设矩阵A的逆矩阵为B，则满足AB=I且A为方阵，其中I为单位矩阵，通常$B=A^{-1}$ 

```python
import numpy as np
from scipy import linalg
A = np.array([[1,3,5],[2,5,1],[2,3,8]])
#array([[1, 3, 5],
#      [2, 5, 1],
#      [2, 3, 8]])
linalg.inv(A)
#array([[-1.48,  0.36,  0.88],
#      [ 0.56,  0.08, -0.36],
#      [ 0.16, -0.12,  0.04]])
# double check
A.dot(linalg.inv(A)) 
#array([[  1.00000000e+00,  -1.11022302e-16,  -5.55111512e-17],
#      [  3.05311332e-16,   1.00000000e+00,   1.87350135e-16],
#      [  2.22044605e-16,  -1.11022302e-16,   1.00000000e+00]])
```

**求解线性方程组：solve(A, b)**

对于线性方程组Ax = b，若方程有解即$|A| \ne 0$ 则有$x = A^{-1}b$

```python
import numpy as np
from scipy import linalg
A = np.array([[1, 2], [3, 4]])
#array([[1, 2],
#      [3, 4]])
b = np.array([[5], [6]])
#array([[5],
#      [6]])
linalg.inv(A).dot(b)  # slow
#array([[-4. ],
#      [ 4.5]])
#A.dot(linalg.inv(A).dot(b)) - b  # check
#array([[  8.88178420e-16],
#      [  2.66453526e-15]])

#方法2：速度更快
np.linalg.solve(A, b) 
array([[-4. ],
      [ 4.5]])
#check
A.dot(np.linalg.solve(A, b)) - b 
#array([[ 0.],
#      [ 0.]])
```

**行列式：det(A)**

[行列式](https://baike.baidu.com/item/%E8%A1%8C%E5%88%97%E5%BC%8F)在数学中，是一个函数，其定义域为det的矩阵A，取值为一个标量，写作det(A)或 | A | 

```python
import numpy as np
from scipy import linalg
A = np.array([[1,2],[3,4]])
linalg.det(A)
#-2.0
```

**范数：norm(a, ord=None, axis=None, keepdims=False)**

计算向量或矩阵范数，根据ord的不同norm函数能够返回不同的矩阵范数和向量范数。

- a为(M, )或者(M, N)类型的ndarray，若axis为None则a必须是1-D或2-D的数组；
- ord为范数的阶数，取值为{非零整数，inf，-inf，‘fro’}；
- axis取值为{int，2-tuple of ints，None}，若为int则表示沿哪个轴计算向量范数，若为元组则对应2-D矩阵的矩阵范数；若为None则a是1-D计算向量范数，a是2-D计算矩阵范数。
- keepdims当设置为True时， the axes which are normed over are left in the result as dimensions with size one

对于向量和矩阵对应的范数计算公式如下
$$
||X|| =
\begin{cases}
    max|X_i| \quad ord = inf \\
    min|X_i| \quad ord=-inf \\
    (\sum_{i}|X_i|^{ord})^{\frac{1}{ord}} \quad |ord| \lt \propto
\end{cases} \\


||A|| = 
\begin{cases}
    max_i\sum_j|a_{ij}| \quad ord = inf \\
    min_i\sum_j|a_{ij}| \quad ord = -inf \\
    max_j\sum_i|a_{ij}| \quad ord = 1 \\
    min_j\sum_i|a_{ij}| \quad ord = -1 \\
    max \sigma_i| \quad ord = 2 \\
    min \sigma_i| \quad ord = -2 \\
    \sqrt{trace(A^HA)} \quad ord = 'fro' \\
\end{cases}
$$

```python
import numpy as np
from scipy import linalg
A=np.array([[1,2],[3,4]])
#array([[1, 2],
#      [3, 4]])

linalg.norm(A)
#5.4772255750516612
linalg.norm(A,'fro') # frobenius norm is the default
#5.4772255750516612
linalg.norm(A,1) # L1 norm (max column sum)
#6
linalg.norm(A,-1)
#4
linalg.norm(A,np.inf) # L inf norm (max row sum)
#7    
```

**线性方程的最小二乘(least-squares)解与伪逆(Pseudo-Inverse)**

假设数据$y_i$ 与数据$x_i$ 是相关的，通过一组系数(Coefficients)$c_i$ 和函数$f_i(x_i)$ 满足模型
$$
y_i = \sum_{j}c_{j}f_{j}(x_i) + \varepsilon_i，其中\varepsilon_i 是数据中的不确定项
$$
采用最小二乘法就是找到一组系数$c_i$ 使得真实值$y_i$ 与预测值之差的平方（消除符号影响）和最小
$$
J(c) = \sum_i|y_i - \sum_{j}c_{j}f_{j}(x_i) |^2
$$
求最小值只需要分别对系数$c_i$ 求偏导数，并令偏导数等于零，求得一组解就能够使得J(c)的值最小
$$
\frac{\partial J}{\partial c_{n}^{*}} = 0 = \sum_i(y_i - \sum_{j}c_{j}f_{j}(x_i))(-f_{n}^{*}(x_i)) \\ or \\
\sum_{j}c_{j}\sum_{i}f_{j}(x_i)f_{n}^{*}(x_{i}) = \sum_{i}y_{i}f_{n}^{*}(x_i) \\
A^HAc = A^Hy \quad where \quad \{A_{ij}\} = f_{j}(x_i)  \quad and \quad  A^HA是可逆的\\
\downarrow \\
c = (A^HA)^{-1}A^Hy = A^{+}y \quad where \; 若A不可逆，则 A^{+}是A的伪逆
$$
因为$A_{ij}=f_j(x_i)$， 则定义的模型可以写为：$y = Ac + \varepsilon$ . `linalg.lstsq(A, y)`方法能够在给定A和y的情况下计算出系数c。此外l`inalg.pinv`和`linalg.pinv2`会计算出矩阵A的伪逆$A^+$

范例：下面例子使用`linalg.lstsq(A, y)` 和`inalg.pinv` 解决数据拟合问题(data-fitting)，下面数据是基于模型，其中给$y_i$ 添加了噪音
$$
y_i = c_1e^{-x_i} + c_2x_i \quad where \ x_{i} = 0.1i \ ，i \in [1, 10]  \ c_1 = 5，c_2 = 4  
$$

```python
import numpy as np
from scipy import linalg
import matplotlib.pyplot as plt

c1, c2 = 5.0, 2.0
i = np.r_[1:11]
#array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])
xi = 0.1*i
#array([ 0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ])
yi = c1*np.exp(-xi) + c2*xi
#array([ 4.72418709,  4.49365377,  4.3040911 ,  4.15160023,  4.0326533 ,
#        3.94405818,  3.88292652,  3.84664482,  3.8328483 ,  3.83939721])
#带噪声的y值
zi = yi + 0.05 * np.max(yi) * np.random.randn(len(yi))

A = np.c_[np.exp(-xi)[:, np.newaxis], xi[:, np.newaxis]]
#array([[ 0.90483742,  0.1       ],
#       [ 0.81873075,  0.2       ],
#       [ 0.74081822,  0.3       ],
#       [ 0.67032005,  0.4       ],
#       [ 0.60653066,  0.5       ],
#       [ 0.54881164,  0.6       ],
#       [ 0.4965853 ,  0.7       ],
#       [ 0.44932896,  0.8       ],
#       [ 0.40656966,  0.9       ],
#       [ 0.36787944,  1.        ]])

# lstsq返回值
# c:        最小二乘的解，为(N,)或(N, K)ndarray
# residues：残差和，squared 2-norm for each column in ``y-Ac``
# rank:     矩阵A的秩
# sigma:    矩阵A的奇异值
c, resid, rank, sigma = linalg.lstsq(A, zi)
#(array([ 5.00278791,  2.10108782]),
# 0.47110363682170298,
# 2,
# array([ 2.58763467,  1.02933937]))

#用模型预测的值
xi2 = np.r_[0.1:1.0:100j]
yi2 = c[0]*np.exp(-xi2) + c[1]*xi2

#查看拟合效果
plt.plot(xi,zi,'x',xi2,yi2)
plt.axis([0,1.1,3.0,5.5])
plt.xlabel('$x_i$')
plt.title('Data fitting with linalg.lstsq')
plt.show()
```

**伪逆矩阵（广义逆矩阵）** 

| 伪逆矩阵方法       | 说明                              |
| ------------ | ------------------------------- |
| linalg.pinv  | Moore-Penrose利用最小二乘法lstsq求解伪逆矩阵 |
| linalg.pinv2 | 利用SVD分解求伪逆矩阵                    |
| linalg.pinvh | 求Hermitian矩阵的伪逆矩阵               |

奇异矩阵或非方阵的矩阵不存在逆矩阵，但可以用函数`linalg.pinv` or `linalg.pinv2` 求矩阵的伪逆矩阵。令A为M*N的矩阵，称矩阵G是A的广义逆矩阵（伪逆矩阵）。
$$
A为M \times N的矩阵，\qquad \qquad \qquad\qquad \qquad \qquad\qquad \qquad \qquad\\
1. 若M > N，则A的广义逆矩阵为：A^+ = (A^HA)^{-1}A^H  \\
2. 若M < N，则A的广义逆矩阵为：A^\# =A^H (AA^H)^{-1}   \\
3. 若M = N，则A的广义逆矩阵为：A^\# =A^+ = A^{-1}  \quad
$$

###2.3 特征值（Eigenvalues）、特征向量（Eigenvectors）

对于矩阵A存在常数$\lambda$以及对应向量v，满足等式$Av = \lambda v$ ，对于$N \times N$的矩阵存在N个特征值（不一定不同），满足多项式的$|A - \lambda I| = 0$根。特征向量v也称为右特征向量，区别于左特征向量$v_{L}^{H}$ ，左特征向量满足
$$
\ v{L}^{H} A = \lambda v{L}^{H} \quad or \quad  A^H v{L} = \lambda^{*} v{H} ，其中H表示共轭向量|矩阵（Hermitian conjugation），\lambda^{*}是\lambda的共轭向量
$$
此外，`linalg.eig` 方法能够解决广义的特征值问题，对于方阵A，B，满足
$$
A v = \lambda B v  \qquad  \qquad \ \ \ 右特征向量\\
A^H v_{L} = \lambda^{*}B^{H}v_{L}   \qquad 左特征向量
$$
同样可以求出对应的特征值和特征向量。实际上，标准的特征值和特征向量是在B=I的情况下求出的。当求解出特征向量后，我们就能够得到矩阵A的一个分解
$$
A = B V  \Lambda V_{-1} \qquad V是列特征向量构成矩阵，\Lambda是有特征值构成的对角矩阵
$$
根据定义，特征向量只取决于常量因子$\lambda$ ，在Scipy中特征向量的的常量因子满足
$$
||v||^2 = \sum_{i}v_{i}^2 = 1
$$
`范例` ：
$$
A = \left [
\begin{matrix}
    1 & 5 & 2 \\
    2 & 4 & 5 \\
    3 & 6 & 2
\end{matrix}
\right ] \\
|A-\lambda I| = (1 - \lambda)[(4 - \lambda)(2 - \lambda)-6] - 5[2(2-\lambda) - 2]  \\ 
+ 2[12 - 3(4 - \lambda)]  \qquad \qquad \\
= - \lambda^3 + 7\lambda^2 + 8\lambda - 3 \qquad \qquad \qquad \  \\
求得： \lambda_{1} = 7.9579，\lambda_{2} = -1.2577，\lambda_{3}=0.2997  \qquad  \quad
$$
**linalg.eig(a, b=None, left=False, right=True, overwrite_a=False, overwrite_b=False, check_finite=True)**

**linalg.eigvals(a, b=None, overwrite_a=False, check_finite=True) 仅仅返回特征值w**

- a要计算特征值和特征向量的矩阵
- b为在计算广义特征值和特征向量时，满足Av = xBv中的矩阵B
- left为True表示计算左特征向量，right默认为True表示返回右特征向量
- overwrite_a是否覆盖a矩阵，overwrite_b是否覆盖b矩阵，为False会提高计算速度；
- check_finite为True是会检查矩阵中的数是不是finite number，设置为False会提高计算速度

​     `返回值` 

- w, 类型为特征值构成(M, )的ndarray
- vl，规范化的左特征向量(M, M)的ndarray，当left=True是返回；
- vr，规范化的右特征向量(M, M)的ndarray，当right=True是返回；

```python
import numpy as np
from scipy import linalg
A = np.array([[1, 2], [3, 4]])
la, v = linalg.eig(A)
l1, l2 = la
# eigenvalues
#(-0.372281323269+0j) (5.37228132327+0j)

v
#array([[-0.82456484, -0.41597356],
#       [ 0.56576746, -0.90937671]])
# first eigenvector
print(v[:, 0])   
[-0.82456484  0.56576746]
 # second eigenvector
print(v[:, 1])  
[-0.41597356 -0.90937671]

# eigenvectors are unitary
print(np.sum(abs(v**2), axis=0))  
[ 1.  1.]

v1 = np.array(v[:, 0]).T
#check the computation
print(linalg.norm(A.dot(v1) - l1*v1)) 
3.23682852457e-16
```

###2.4 矩阵分解(Decomposition)

**奇异值分解（SVD，Singular Value Decomposition）** 

奇异值分解可以看成是特征值问题的扩展，`针对非方阵` ,  设A为$M \times N$ 的矩阵，满足$A^HA、AA^H分别是N \times N、M \times M 的 Hermitian方阵$ ，Hermitian方阵的特征值是`实数且是非负的`，并且在Hermitian方阵$A^HA、AA^H$中`最多有min(M, N)个相同的非零特征值` 。设这些非负特征值为$\sigma_{i}^2$ ，那么这些特征值开根号后的即为矩阵A的奇异值，矩阵$A^HA$ 的列特征向量构成了$N \times N$的unitary矩阵$V $ ，而矩阵$AA^H$ 的列特征向量构成的$M \times M$ 的unitary矩阵U，奇异值构成的$M \times N$对角矩阵$\Sigma$  ，则：
$$
A = U \Sigma V^H \\
 hermitian \  matrix \ D \ 满足 D^H = D \\
 unitary \ matrix \ D \ 满足 D^HD = I = DD^H \rightarrow D^{-1} = D^H
$$
就是A的一个奇异分解。每一个矩阵都存在一个奇异值分解。有时候奇异值称为矩阵的A的谱(spectrum)。`linalg.svd` 返回$U，\sigma_{i} 数组，V^H $ ，`linalg.diagsvd` 返回奇异值构成的对角矩阵$\Sigma$ `linalg.svdvals` 仅仅返回矩阵的奇异值。

```python
import numpy as np
from scipy import linalg
A = np.array([[1,2,3],[4,5,6]])
#array([[1, 2, 3],
#      [4, 5, 6]])

M,N = A.shape
U,s,Vh = linalg.svd(A)
Sig = linalg.diagsvd(s,M,N)

U, Vh = U, Vh
#array([[-0.3863177 , -0.92236578],
#      [-0.92236578,  0.3863177 ]])
#Sig
#array([[ 9.508032  ,  0.        ,  0.        ],
#      [ 0.        ,  0.77286964,  0.        ]])
#Vh
#array([[-0.42866713, -0.56630692, -0.7039467 ],
#      [ 0.80596391,  0.11238241, -0.58119908],
#      [ 0.40824829, -0.81649658,  0.40824829]])

U.dot(Sig.dot(Vh)) #check computation
#array([[ 1.,  2.,  3.],
#      [ 4.,  5.,  6.]])
```

**LU分解**

对于矩阵$M \times N $ 的A，LU分解后得到
$$
A = P \ L \ U  \\
其中P是M \times M的permutation \ matrix（单位矩阵按行随机排列得到的矩阵） \\
L是M \times K的下三角矩阵[K = min(M, N)]  \\
U是K \times N的上三角矩阵
$$
LU分解通常用于解决simultaneous equations，并且等式左边不变而右边经常变动
$$
Ax_i = b_i，（对于不同的b_i） \\
\downarrow \\
PLUx_i = b_i
$$

>An initial time spent factoring A allows for very rapid solution of similar systems of equations in the future. If the intent for performing LU decomposition is for solving linear systems then the command `linalg.lu_factor` should be used followed by repeated applications of the command `linalg.lu_solve` to solve the system for each new right-hand-side.

**linalg.lu(a, permute_l=False, overwrite_a=False, check_finite=True)**

- 默认返回值为P， L，U
- 若permute_l为True，则返回pl，U

**linalg.lu_factor(a, overwrite_a=False, check_finite=True)**

- 计算矩阵A 的pivoted LU分解
- 返回值为N*N的矩阵LU和N长度的数组piv

**linalg.lu_solve(lu_and_piv, b, trans=0, overwrite_b=False, check_finite=True)**

- lu_and_piv为元组(LU， piv)
- b为Ax=b方程组中矩阵b
- trans取值为{0, 1, 2}分别对应：a x   = b， a^T x = b，a^H x = b
- 返回值为x数组即方程组的解

**Cholesky decomposition**

Cholesky分解是LU分解的一个特例，针对Hermitian矩阵（$A=A^H \ and \ x^H A x \ge 0 \ for \ all \ x$），则A的分解可以写为
$$
A = U^H U  \qquad (U是上三角矩阵)\\
A = L L^H  \qquad (L是下三角矩阵，L = U^H)
$$
同样存在方法`linalg.cholesky` ，` linalg.cho_factor`，`linalg.cho_solve`

**QR分解**

QR分解又称为a polar decomposition，对于任意$M \times N$ 的矩阵能够找到$M \times N$ 的unitary矩阵Q和$M \times N$ 上三角矩阵R，满足
$$
A = QR \\
若A的SVD分解是已知的，则有 A = U \Sigma V^H = QR，则有Q = U  \ ， R = \Sigma V^h
$$

| QR分解相关方法                     | 说明                                       |
| ---------------------------- | ---------------------------------------- |
| linalg.qr(a)                 | 返回Q, R, P                                |
| linalg.qr_multiply(a, c)     | 进行QR分解，并将Q乘以c返回，返回Qc, R, P               |
| linalg.qr_update(Q, R, u, v) | If ``A = Q R`` is the QR factorization of ``A``, return the QR factorization of ``A + u v**T`` for real ``A`` or ``A + u v**H`` for complex ``A`` ，返回Q1, R1 |
| linalg.qr_delete             | If ``A = Q R`` is the QR factorization of ``A``, return the QR  factorization of ``A`` where ``p`` rows or columns have been removed starting at row or column ``k``. |
| linalg.qr_insert             | If ``A = Q R`` is the QR factorization of ``A``, return the QR factorization of ``A`` where rows or columns have been inserted starting at row or column ``k``. |



















